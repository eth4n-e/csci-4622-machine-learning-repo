{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 2 - Decision Trees and Ensemble Methods\n",
    "## CSCI 4622 - Fall 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Name**: $<$insert name here$>$\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment is due on Canvas by **11:59PM on September 26**.\n",
    "\n",
    "Submit only this Jupyter notebook to Canvas. Do not compress it using tar, rar, zip, etc.\n",
    "Your solutions to analysis questions should be done in Markdown directly below the associated question.\n",
    "\n",
    "Remember that you are encouraged to discuss the problems with your classmates and instructors,\n",
    "but **you must write all code and solutions on your own**, and list any people or sources consulted.\n",
    "The only exception to this rule is that you may copy code directly from your own solution to homework 1 or labs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "overview",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Overview \n",
    "\n",
    "Your task for this homework is to build a decision tree classifier from scratch. Of course, we provide some initial classes that you'll be editing.\n",
    "Since the other two problems will use the scikit-learn's DecisionTreeClassifier, your solution does not have to be efficient as long as it passes the sanity checks in a reasonable time (typically less than ~1min).\n",
    "\n",
    "The last problem requires a _weak learner_, so we'll use a decision tree that yields low performance. But with _Ensemble Methods_, we will be able to improve the performance by aggregating predictions from multiple weak learners.\n",
    "For the ensemble methods, we'll explore bagging, Random Forest, and boosting (AdaBoost).\n",
    "\n",
    "Any Machine Learning interview will almost certainly have a question or two about decision trees and how they're trained.\n",
    "So understanding the code and trying to implement everything on your own will be the best way to prepare for such interviews.\n",
    "\n",
    "Also remember, if your code is correct then the sanity checks should pass without any major issue.\n",
    "But if the sanity checks pass that does not necessarily imply your code is 100% correct.\n",
    "\n",
    "Happy coding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import helpers\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 - Decision Trees [50 points + 4 points]\n",
    "***\n",
    "The goal of this problem is to implement the core elements of the Decision Tree classifier.\n",
    "We do not expect a highly efficient implementation of the functions since we will be using the implementation from scikit-learn in later problems.\n",
    "\n",
    "We'll be testing our implementation on a simple toy dataset, which we will call the \"College Degree\" dataset:\n",
    "\n",
    "|Age|Income|Single| Has Pets | College Degree|\n",
    "|:------:|:-----------:| :----------:| :----------:|:--:|\n",
    "|20| 37000| 1| 0|0|\n",
    "|32| 50000| 0| 0|0|\n",
    "|24| 46000| 1| 1|0|\n",
    "|28| 52000| 1| 1|1|\n",
    "|28| 28000| 0| 1|0|\n",
    "|22| 54000| 0| 1|1|\n",
    "|28| 50000| 0| 0|1|\n",
    "|26| 36000| 0| 0|1|\n",
    "|24| 45000| 1| 1|0|\n",
    "|33| 45000| 0| 0|1|\n",
    "|34| 50000| 1| 1|0|\n",
    "|29| 51000| 1| 0|1|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "features = np.array([[20, 37000, 1, 0],\n",
    "                     [32, 50000, 0, 0],\n",
    "                     [24, 46000, 1, 1],\n",
    "                     [28, 52000, 1, 1],\n",
    "                     [28, 28000, 0, 1],\n",
    "                     [22, 54000, 0, 1],\n",
    "                     [28, 50000, 0, 0],\n",
    "                     [26, 36000, 0, 0],\n",
    "                     [24, 45000, 1, 1],\n",
    "                     [33, 45000, 0, 0],\n",
    "                     [34, 50000, 1, 1],\n",
    "                     [29, 51000, 1, 0]])\n",
    "labels = np.array([0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Computing Node Labels\n",
    "Each leaf node (terminal node) in a decision tree has a label value assigned to it. The same label will be assigned to all samples that reach the leaf node during the prediction.\n",
    "\n",
    "**Q1.1** [5 points] Complete `compute_label` to return the label that should be assigned to the leaf node based on training labels in `y`.\n",
    "If more than one label are possible, choose the one with the highest value (e.g, if both `0` and `1` are equally likely, choose `1`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "a11",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_label(node_labels):\n",
    "\n",
    "    # Workspace 1.1\n",
    "    # TODO: Return the label that should be assigned to the leaf node\n",
    "    # In case of multiple possible labels, choose the one with the highest value\n",
    "    # Make no assumptions about the number of class labels\n",
    "    label = None\n",
    "    #BEGIN\n",
    "    #END\n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide below the LeafNode implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class LeafNode:\n",
    "    def __init__(self, node_labels):\n",
    "        \"\"\" Initialize the leaf node\n",
    "        Args:\n",
    "            y: 1-d array containing labels, of shape (num_points,)\n",
    "        \"\"\"\n",
    "        self.label = compute_label(node_labels)\n",
    "\n",
    "    @staticmethod\n",
    "    def is_terminal():\n",
    "        return True\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.label * np.ones(X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%run -i tests leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Quantifying impurity\n",
    "The tree also contains _decision nodes_. They can either be parents of: leaf nodes, decision nodes, or a combination of the two.\n",
    "\n",
    "Each decision node has a left and a right child. A node is branched out (parent node) **when we can reduce the impurity** by splitting\n",
    "the training instances based on a certain threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll need to choose a impurity measure. For this problem, we will use the _gini impurity_ (information entropy is also commonly used here, which computes *uncertainty*).\n",
    "\n",
    "\\begin{align}\n",
    "\\text{Gini}(y) = 1 - \\sum_{c=1}^{n} p_{c}^2\n",
    "\\end{align}\n",
    "\n",
    "where $p_c$ is the probability of the occurrence of class $c$ among the $n$ labels in $y$\n",
    "\n",
    "**Q1.2** [5 points] Complete the function `gini` that returns the gini impurity of labels in `y`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "a12",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def gini(y):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        y: 1-d array contains labels, of shape (num_points,)\n",
    "    Returns: float, gini impurity of the values in y\n",
    "    \"\"\"\n",
    "    gini = 0\n",
    "    # Workspace 1.2\n",
    "    # TODO: Compute the gini impurity of the labels\n",
    "    #BEGIN\n",
    "    #END\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cell, uncomment to run the tests\n",
    "%run -i tests gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "When we create a decision node, we decide to split our samples $T$ to two parts $T_L$ and $T_R$, and we want to compute how much this split reduces the impurity.\n",
    "\n",
    "**Q1.3** [5 points] Using the impurity measure $\\mathcal{u}$, what is the expression of the expected impurity reduction if we split $T$ into $T_L, T_R$ ?\n",
    "\n",
    "You can use LaTeX markdown to [type the equations](https://www.fabriziomusacchio.com/blog/2021-08-10-How_to_use_LaTeX_in_Markdown/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "a13",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "##### Workspace 1.3\n",
    "\n",
    "#BEGIN\n",
    "\n",
    "#END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Note: If we were to use entropy as our uncertainty measure, the uncertainty reduction in this case is also called _information gain_.\n",
    "(reducing the entropy implies that the partitioning decision variable and the labels have a higher mutual information).\n",
    "\n",
    "Instead, for this assignment we use gini impurity, which reduces the cluster impurity, and is faster to compute than entropy. Gini is also easier to compute by hand as a sanity check.\n",
    "\n",
    "**Q1.4** [5 points] Complete the `impurity_reduction` function to return the reduction of the split using the gini impurity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "a14",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def impurity_reduction(y, left_indices, right_indices):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        y: all labels\n",
    "        left_indices: the indices of the elements of y that belong to the left child\n",
    "        right_indices: the indices of the elements of y that belong to the right child\n",
    "    Returns: impurity reduction of the split\n",
    "    \"\"\"\n",
    "    reduction = 0\n",
    "    # Workspace 1.4\n",
    "    #BEGIN\n",
    "    #END\n",
    "    return reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cell, uncomment to run the tests\n",
    "%run -i tests reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Splitting data\n",
    "\n",
    "We'll use `best_split` to look up for the feature and threshold that yields the partition with the best impurity reduction.\n",
    "\n",
    "- For each feature:\n",
    "    - Compute all possible thresholds (use `split_values`)\n",
    "    - For each threshold:\n",
    "        - Split to `(left_indices, right_indices)` based on the threshold\n",
    "        - Compute the impurity reduction of the split\n",
    "- Returns the feature and the threshold that yield the highest impurity reduction (and the reduction value)\n",
    "<br>\n",
    "\n",
    "**Q1.5** [8 points] Complete `best_split`. In case there are multiple possible solutions, return the first one encountered.\n",
    " \n",
    " _Hint: `split_values` is provided as a helper function for finding splits on numeric variables. It takes the feature column and returns the set of thresholds midway between each value. Use print to display the behavior if still not clear._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "a15",
     "locked": false,
     "points": 8,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def split_values(feature_values):\n",
    "    \"\"\" Helper function to return the split values. if feature consists of the values f1 < f2 < f3 then\n",
    "    this returns [(f2 + f1)/2, (f3 + f2)/2]\n",
    "    Args:\n",
    "        feature_values: feature_values: 1-d array of shape (num_points)\n",
    "    Returns:  array of shape (max(m-1, 1),) where m is the number of unique values in feature_values\n",
    "    \"\"\"\n",
    "    unique_values = np.unique(feature_values)\n",
    "    if unique_values.shape[0] == 1:\n",
    "        return unique_values\n",
    "    return (unique_values[1:] + unique_values[:-1]) / 2\n",
    "\n",
    "\n",
    "def best_split(X, y):\n",
    "    \"\"\" Find the feature id, threshold, indices, and reduction for the best split\n",
    "    Args:\n",
    "        X: features array, shape (num_samples, num_features)\n",
    "        y: labels of instances in X, shape (num_samples)\n",
    "    Returns: the best split related information.\n",
    "    \"\"\"\n",
    "\n",
    "    best_feature_id, best_threshold, best_left_indices, best_right_indices = None, None, None, None\n",
    "    best_reduction = -np.inf\n",
    "\n",
    "    # Workspace 1.5\n",
    "    # TODO: Complete the function as detailed in the question and return description\n",
    "    # NOTE: See specification in Q1.6:\n",
    "    #       if feature_value == threshold, it should end up in the **left** child.\n",
    "    for feature_id in range(X.shape[1]):\n",
    "        for threshold in split_values(X[:, feature_id]):\n",
    "        #BEGIN\n",
    "        #END\n",
    "    return best_feature_id, best_threshold, best_left_indices, best_right_indices, best_reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cell, uncomment to run the tests\n",
    "# If you chose to not use split_values, then this test will likely fail\n",
    "%run -i tests split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision (non-leaf) nodes\n",
    "Note that samples for which the `feature_id` value is <= `feature_threshold` will go into the `left_child`. We should construct our decision tree as such.\n",
    "We define the DecisionNode class below.\n",
    "\n",
    "- The `add_importance` method is relevant to Bonus Q1.10 later in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "a110",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class DecisionNode:\n",
    "    def __init__(self, feature_id, threshold, left_child, right_child):\n",
    "        self.feature_id = feature_id\n",
    "        self.threshold = threshold\n",
    "        self.left = left_child\n",
    "        self.right = right_child\n",
    "\n",
    "    @staticmethod\n",
    "    def is_terminal():\n",
    "        return False\n",
    "\n",
    "    def add_importance(self, importances: dict, X, y):\n",
    "        # Workspace 1.10\n",
    "        # Bonus question\n",
    "        # Note that dictionaries are passed by reference and not by value\n",
    "        #BEGIN\n",
    "        #END\n",
    "        return importances\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = np.zeros((X.shape[0]))\n",
    "        left_indices = np.where(X[:, self.feature_id] <= self.threshold)[0]\n",
    "        right_indices = np.where(X[:, self.feature_id] > self.threshold)[0]\n",
    "        y_pred[left_indices] = self.left.predict(X[left_indices])\n",
    "        y_pred[right_indices] = self.right.predict(X[right_indices])\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting nodes together: building the tree\n",
    "\n",
    "Now we tackle the core of a decision tree. The tree is built in a recursive way. The recursion in `build_tree` works as follows:\n",
    "- Parameters: `min_samples_split`, `depth`\n",
    "- Inputs: `X`, `y`\n",
    "- Base case of the recursion, return a leaf node if either:\n",
    "    - `depth` is 0\n",
    "    - `y` contains less than `min_samples_split` elements\n",
    "    - There is no impurity reduction (reduction<=0 for all splits)\n",
    "- Recursion (there is a split with reduction > 0):\n",
    "    - create a decision node with left and right child nodes with `depth - 1`\n",
    "    - return the decision node\n",
    "\n",
    "The left child node will contain instances for which the feature with index `best_feature` is strictly <\n",
    "`best_threshold` of the split. The right child takes the remaining instances.\n",
    "\n",
    "\n",
    "**Q1.6** [10 points] Complete `build_tree` method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "a16",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def build_tree(X, y, depth=-1, min_samples_split=2):\n",
    "    if depth == 0 or len(y) < min_samples_split:\n",
    "        # we reached the maximum depth or we don't have more than the minimum number of samples in the leaf\n",
    "        tree = LeafNode(y)\n",
    "    else:\n",
    "        # Get the feature, threshold and information_gain of the best split\n",
    "        feature_id, threshold, left_indices, right_indices, reduction = best_split(X, y)\n",
    "        # reduction = 0 occurs when the labels have the same distribution in the child nodes\n",
    "        # which means that the entropy of the children is the same as the parent's so we don't need to split\n",
    "        # Workspace 1.6\n",
    "        # TODO: if needed, create the left and right child nodes with depth - 1, return the decision node\n",
    "        #BEGIN\n",
    "        #END\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.7** [4 points] Complete the `score` method that returns the accuracy on the given data (you can use `sklearn.metrics`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "a17",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "\n",
    "    def __init__(self, max_depth=-1, min_samples_split=2):\n",
    "        \"\"\" Initialize the decision tree\n",
    "        Args:\n",
    "            max_depth: maximum depth of the tree\n",
    "            min_samples_split: minimum number of samples required for a split\n",
    "        \"\"\"\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree = None\n",
    "        self.num_features = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X: Training samples\n",
    "            y: training labels\n",
    "        Return:\n",
    "             trained decision tree\n",
    "        \"\"\"\n",
    "        self.tree = build_tree(X, y, self.max_depth, self.min_samples_split)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Loops through rows of X and predicts the labels one row at a time\n",
    "        \"\"\"\n",
    "        return self.tree.predict(X)\n",
    "\n",
    "    def feature_importance(self, X, y):\n",
    "        \"\"\" Compute the importance of each feature in the decision tree\n",
    "         Only relevant to the bonus question\n",
    "        \"\"\"\n",
    "        feat_importance = {k:0 for k in range(X.shape[1])}\n",
    "        if not self.tree.is_terminal():\n",
    "            self.tree.add_importance(feat_importance, X, y)\n",
    "        feat_importance = {k: v/sum(feat_importance.values()) for k,v in feat_importance.items()}\n",
    "        return feat_importance\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\" Return the mean accuracy on the given test data and labels.\n",
    "        Args:\n",
    "            X: Test samples, shape (num_points, num_features)\n",
    "            y: true labels for X, shape (num_points,)\n",
    "        Return:\n",
    "            mean accuracy\n",
    "        \"\"\"\n",
    "        accuracy = 0\n",
    "        # Workspace 1.7\n",
    "        #BEGIN\n",
    "        #END\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Test cell, uncomment to run the tests\n",
    "# If you chose to not use split_values, then this test will likely fail\n",
    "%run -i tests build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Q1.8** [4 points] Using `min_samples_split=2`, what is the minimum depth so that our `DecisionTree` fits perfectly our dataset `(features, labels)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "a18",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Workspace 1.8\n",
    "# To show that the minimum required depth is n, you can provide the accuracy for depth = (n-1) and depth = n\n",
    "#BEGIN\n",
    "#END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We provide an example below to display the structure of a decision tree.\n",
    "\n",
    "**Q1.9** (4points) Edit the example below to show the tree for the required minimum depth found in 1.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "a19",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tree = DecisionTree(max_depth=3, min_samples_split=2).fit(features, labels)\n",
    "helpers.print_tree(tree, [\"age\", \"income\", \"single\", \"has_pets\"])\n",
    "#BEGIN\n",
    "#END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bonus\n",
    "Now we can be a bit more ambitious and compute the importance of each feature in our decision tree. The importance of feature $f$\n",
    "is the sum of the weighted impurity reduction of decision nodes that are split based on the feature $f$.\n",
    "\n",
    "The weighted impurity reduction of $node_i$ is the following:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{N_{\\text{node}_i}}{N_\\text{total}} \\times \\textrm{Reduction}({\\text{node}_i}),\n",
    "\\end{align}\n",
    "\n",
    "where $N$ is the total number of training samples, and $N_{\\text{node}_i}$ is the number of training samples that reach the decision node $node_i$.\n",
    "\n",
    "Since we scale the feature importances in `DecisionTree` to sum to 1, we don't have to divide by $N_\\text{total}$\n",
    "and we can simply use:\n",
    "\n",
    "\\begin{align}\n",
    "\\text{weighted reduction}(\\text{node}_i) = N_{\\text{node}_i} \\times \\textrm{Reduction}({\\text{node}_i}),\n",
    "\\end{align}\n",
    "\n",
    "Practically, we use a dictionary `feat_importance` that maps feature indices to their importances.\n",
    "- Start with `feat_importance[f]=0` for all `f`\n",
    "- Start the recursion from the root node:\n",
    "    - Current node is split based on feature `i`\n",
    "    - add weighted impurity reduction to `feat_importance[i]`\n",
    "    - ask right and left child to do the same\n",
    "- Scale the values in `feat_importance` to sum to 1\n",
    "- return `feat_importance`\n",
    "\n",
    "\n",
    "**(Bonus)Q1.10** [4 points] Complete `DecisionNode`'s `feature_importance`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment to test\n",
    "%run -i tests importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 - Decision Tree Ensembles [50 points]\n",
    "---\n",
    "\n",
    "\n",
    "We've seen that a DecisionTreeClassifier with depth = 3 is far from being the best performing even on our toy College Degree dataset.\n",
    "\n",
    "In this problem, we will introduce 3 ensemble methods to _boost_ the performance of this poor and underestimated weak learner.\n",
    "\n",
    "First, we'll need a fancier dataset to see useful results. We are going to predict house price levels using ensembles of trees. We start by loading preprocessed data that we'll use. Instead of the \"California Housing\" dataset from Problem Set 1, we will use the [Ames Housing dataset](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)\n",
    "\n",
    "Since the original House Prices are presented as numeric variables (i.e. for performing regression), we have to transform `HousePrices.y` to discrete values reflecting price level.\n",
    "\n",
    "|Price range| Label|\n",
    "|:----------:|--:|\n",
    "| $ P < $110000|0|\n",
    "|110000$\\leq P < $ 150000| 1 |\n",
    "|150000$ \\leq P < $ 210000| 2 |\n",
    "|210000$ \\leq P $ | 3 |\n",
    "\n",
    "\n",
    "**Q2.1** [4 points] Transform `house_prices.y` following the table above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "a31",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import data\n",
    "\n",
    "house_prices = data.HousePrices()\n",
    "# Workspace 2.1\n",
    "# TODO: Discretize house_prices.y\n",
    "#BEGIN\n",
    "#END\n",
    "print(np.unique(house_prices.y), house_prices.X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%run -i tests discretize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=3, min_samples_leaf=0.1).fit(house_prices.X, house_prices.y)\n",
    "print(\"Accuracy on training set:\", tree.score(house_prices.X, house_prices.y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell above show that even when evaluated on the training data, a decision tree of depth 3 does not perform well\n",
    "\n",
    "Whenever we need to generate a new instance of our weak learner, we'll have to call `get_weak_leaner`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_weak_learner():\n",
    "    \"\"\"Return a new instance of out chosen weak learner\"\"\"\n",
    "    return DecisionTreeClassifier(max_depth=3, min_samples_leaf=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Start by completing the `Evaluator` class that we'll use to evaluate different ensemble methods.\n",
    "\n",
    "\n",
    "**Q2.2** [6 points] Complete the `evaluate_model` class to fit the model that is passed in as an argument, and store the accuracy and running time.\n",
    "\n",
    "Since we don't have a validation set, you have to use [StratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html) (`self.k_fold`) to perform a 3-fold cross validation and store the weighted average precision over the 3 folds\n",
    "\n",
    "You can use the function `plot_metrics` to show and compare different statistics of each model in a bar chart.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "a32",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Evaluator:\n",
    "    \"\"\"\n",
    "        Test multiple model performance\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset):\n",
    "        \"\"\" Initialize Evaluator\n",
    "        Args:\n",
    "            dataset: dataset containing Training and Test sets\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.execution_time = {}  # dictionary with key: model name, value: time taken to fit and score the model\n",
    "        self.scores = {}  # dictionary with key: model name, value: weighted average precision\n",
    "        self.score_name = 'WAP'\n",
    "        # See: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html\n",
    "        self.k_fold = StratifiedKFold(3, shuffle=True, random_state=42)\n",
    "\n",
    "    def evaluate_model(self, model, name):\n",
    "        \"\"\" Fit the model using the training data and save the evaluation score on the test fold\n",
    "        Args:\n",
    "            model: classifier to evaluate, has fit and predict methods\n",
    "            name: name of model\n",
    "        \"\"\"\n",
    "        start = time()\n",
    "        # Workspace 2.2\n",
    "        # TODO: Fit the model on the 3 different folds and store the average accuracy in self.score[name]\n",
    "        #BEGIN\n",
    "        #END\n",
    "        self.execution_time[name] = time() - start\n",
    "\n",
    "    def print_results(self):\n",
    "        \"\"\"\n",
    "            print results for all models trained and tested.\n",
    "        \"\"\"\n",
    "        models_cross = pd.DataFrame({\n",
    "            'Model': list(self.scores.keys()),\n",
    "            self.score_name: list(self.scores.values()),\n",
    "            'Execution time': list(self.execution_time.values())})\n",
    "        print(models_cross.sort_values(by=self.score_name, ascending=False))\n",
    "\n",
    "    def plot_metrics(self):\n",
    "        \"\"\"\n",
    "        Plot bar chart, one for each statistic (metric, score, running time)\n",
    "        \"\"\"\n",
    "        fig, axs = plt.subplots(1, 2)\n",
    "        fig.set_figheight(6), fig.set_figwidth(18)\n",
    "        p = 0\n",
    "        for stats, name in zip([self.scores, self.execution_time],\n",
    "                               [self.score_name, \"Elapsed time\"]):\n",
    "            left = [i for i in range(len(stats))]\n",
    "            height = [stats[key] for key in stats]\n",
    "            tick_label = [key for key in stats]\n",
    "            axs[p].set_title(name)\n",
    "            axs[p].bar(left, height, tick_label=tick_label, width=0.5)\n",
    "            p += 1\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Q2.3** [3 points] Test `Evaluator.evaluate_model` using our weak learner returned by `get_weak_learner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "a33",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create a handler for ensemble_test, use the created handler for fitting different models.\n",
    "ensemble_handler = Evaluator(house_prices)\n",
    "# Workspace 3.3\n",
    "# TODO: Initialize weak learner and evaluate it using evaluate_model\n",
    "#BEGIN\n",
    "#END\n",
    "ensemble_handler.print_results()\n",
    "ensemble_handler.plot_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bagging:**\n",
    "\n",
    "The first Ensemble technique we deal with is called _Bagging_ (Bootstrap AGGregatING).\n",
    "Bagging consists of training a number of weak learners using randomly sampled instances from our data (**with replacement**). We have to start\n",
    "by choosing the number of estimators we want to use. Then for each estimator, we sample a random subset of the data to fit the estimator.\n",
    "\n",
    "To compute the prediction, we sum the prediction probabilities of the estimators and return the label that has the highest\n",
    "accumulated probabilities.\n",
    "\n",
    "**Q2.4** [5 points] First, complete `sample_data` to return a random sample of size `sample_ratio * len(X_train)` of features and labels\n",
    "    - *Hint*: see the numpy.random module.\n",
    "\n",
    "**Q2.5** [6 points] Complete the `fit` method by instantiating `n_estimators` of our weak leaner, each trained on a random sample of the data\n",
    "\n",
    "**Q2.6** [5 points] Complete the `predict` method to return the most likely label by combining the estimators predictions.\n",
    "\n",
    "Instead of the majority vote used in KNNClassifier, you should use the `predict_proba` method of `DecisionTreeClassifier`.\n",
    "[See Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.predict_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "abagging",
     "locked": false,
     "points": 16,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class BaggingEnsemble(object):\n",
    "\n",
    "    def __init__(self, n_estimators, sample_ratio=1.0):\n",
    "        \"\"\"\n",
    "        Initialize BaggingEnsemble\n",
    "        :param n_estimators: number of estimators/weak learner to use\n",
    "        :param sample_ratio: ratio of the training data to sample\n",
    "        \"\"\"\n",
    "        self.n_estimators = n_estimators\n",
    "        self.sample_ratio = sample_ratio\n",
    "        self.estimators = []  # List used in fit method to store the trained estimators\n",
    "\n",
    "    def sample_data(self, X_train, y_train):\n",
    "        X_sample, y_sample = None, None\n",
    "        # Workspace 2.4\n",
    "        # TODO: sample random subset of size sample_ratio * len(X_train), sampling is with replacement (iid)\n",
    "        #BEGIN\n",
    "        #END\n",
    "        return X_sample, y_sample\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Train the different estimators on sampled data using provided training samples\n",
    "        :param X_train: training samples, shape (num_samples, num_features)\n",
    "        :param y_train: training labels, shape (num_samples)\n",
    "        :return: self\n",
    "        \"\"\"\n",
    "        np.random.seed(42)  # Keep it to get consistent results across runs, you can change the seed value\n",
    "        self.estimators = []\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            # Workspace 2.5\n",
    "            #BEGIN\n",
    "            #END\n",
    "        return self\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        Predict the labels of test samples\n",
    "        :param X_test: array of shape (num_points, num_features)\n",
    "        :return: 1-d array of shape (num_points)\n",
    "        \"\"\"\n",
    "        predicted_proba = 0\n",
    "        answer = 0\n",
    "        # Workspace 2.6\n",
    "        # TODO: go through the trained estimators and accumulate their predicted_proba to get the mostly likely label\n",
    "        #BEGIN\n",
    "        #END\n",
    "        return answer\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return np.mean(self.predict(X) == y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This cell should run without errors\n",
    "ensemble_handler.evaluate_model(BaggingEnsemble(10, 0.9), 'Bagging')\n",
    "ensemble_handler.print_results()\n",
    "ensemble_handler.plot_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "qforest",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Random Forest\n",
    "\n",
    "Random Forest has an additional layer of randomness compared to Bagging: we also project the dataset into a lower dimensional subspace.\n",
    "The rest of the implementation should be similar if not exactly the same as Bagging. In addition to keeping track of the estimators, we also need to store the projection matrix associated with the estimator (since each estimator operates on a different subspace).\n",
    "\n",
    "First, we have to generate the random subspaces that we will project into. We do so by generating a random orthonormal basis of the subspace as follows:\n",
    "- Input space dimension n, subspace dimension m\n",
    "- Generate a random normal `G` matrix of shape (n,m): entries have mean 0 and standard deviation 1\n",
    "- Perform the reduced Q,R decomposition on `G` to get the orthonormal basis matrix `Q` of shape (m,n)\n",
    "\n",
    "Then to project n features to m features, we right multiply by `Q`\n",
    "\n",
    "**Q2.7** [5 points] First, complete `random_selection` to randomly sample a subset of the features (with replacement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "a37",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def random_selection(input_dim, output_dim):\n",
    "    \"\"\" Randomly sample output_dim indices in range [0, input_dim-1]\n",
    "    Returns:\n",
    "        indices array of size (output_dim,)\n",
    "    \"\"\"\n",
    "    assert input_dim >= output_dim\n",
    "    # Workspace 2.7\n",
    "    selected_features = None\n",
    "    #BEGIN\n",
    "    #END\n",
    "    return selected_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2.8** [3 points] Complete `sample_data` by defining the `input_dim`, `output_dim` for the random selection of features and the `indices` of the randomly picked samples (similar to bagging)\n",
    "\n",
    "**Q2.9** [5 points] Complete `fit` by building `n_estimators` of DecisionTreeClassifier, each trained on random projection of the data.\n",
    "Make sure to keep track of the projection matrix for each estimator to use them in the prediction step\n",
    "\n",
    "**Q2.10** [4 points] Complete `predict` method to return the most likely label by combining different estimators predictions. Instead of the majority vote used in KNNClassifier, you should use `predict_proba` method DecisionTreeClassifier:\n",
    "[Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.predict_proba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "aforest",
     "locked": false,
     "points": 12,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class RandomForest(BaggingEnsemble):\n",
    "\n",
    "    def __init__(self, n_estimators, sample_ratio=1.0, features_ratio=1.0):\n",
    "        super(RandomForest, self).__init__(n_estimators, sample_ratio)\n",
    "        self.features_ratio = features_ratio\n",
    "        self.estimators = []  # to store the estimator\n",
    "        self.selections = []  # to store the feature indices used by each estimator\n",
    "\n",
    "    def sample_data(self, X_train, y_train):\n",
    "\n",
    "        input_dim = None\n",
    "        output_dim = None\n",
    "        indices = None\n",
    "        # Workspace 2.8\n",
    "        #BEGIN\n",
    "        #END\n",
    "        selected_features = random_selection(input_dim, output_dim)\n",
    "        return X_train[indices][:, selected_features], y_train[indices], selected_features\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        # np.random.seed(42)  # keep to have consistent results across run, you can change the value\n",
    "        self.estimators = []  # to store the estimator\n",
    "        self.selections = []\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            # Workspace 2.9\n",
    "            # TODO: sample data with random subset of rows and features using sample_data\n",
    "            # Hint: keep track of the projections to use in predict\n",
    "            #BEGIN\n",
    "            #END\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        predicted_proba = 0\n",
    "        answer = 0\n",
    "        # Workspace 2.10\n",
    "        # TODO: compute cumulative sum of predict proba from estimators and return the labels with highest likelihood\n",
    "        #BEGIN\n",
    "        #END\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This cell should run without errors\n",
    "ensemble_handler.evaluate_model(RandomForest(50, sample_ratio=0.7, features_ratio=0.1), 'RandomForest')\n",
    "ensemble_handler.print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2.11** [4 points] Add different ensemble methods to the handler (try different parameters), plot, show, and compare them.\n",
    "What's the best weighted average precision we can get? What's the best accuracy? Which ensemble method achieves each of them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "a310",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create a handler for ensemble_test, use the created handler for fitting different models.\n",
    "ensemble_handler = Evaluator(house_prices)\n",
    "ensemble_handler.evaluate_model(get_weak_learner(), 'weak_learner')\n",
    "# Workspace 2.11.a\n",
    "# TODO Add multiple instances of the ensemble methods. Plot and compare their performance\n",
    "# You can also add best tree from problem 3\n",
    "#BEGIN\n",
    "#END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "a49b",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "#### Write-up 2.11.b\n",
    "#BEGIN\n",
    "#END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Multi-class AdaBoost (Bonus) [7 points]\n",
    "\n",
    "There are different methods of boosting, but we'll focus in this problem on Adaptive Boosting (AdaBoost).\n",
    "The logic of AdaBoost is to \"push\" each new learner to give more importance to previously misclassified data. We present\n",
    "below the multiclass variant of AdaBoost [SAMME](https://web.stanford.edu/~hastie/Papers/samme.pdf). We denote $K$ the number of classes.\n",
    "\n",
    "AdaBoost is performed by increasing the weights of misclassified samples after each iteration:\n",
    "- Input: m samples $(X_i, y_i)_{i\\in [m]}$, number of boosting rounds $N$\n",
    "- Start with equal samples weights $W = (w_i), $ where   $w_i = \\frac{1}{\\texttt{n_samples}}$\n",
    "- at round j:\n",
    "    - Train estimator $h_j$ using current weights $W$\n",
    "    - Get the predicted $(\\hat{y}_i)$ on the training data using $h_j$\n",
    "    - Find the weighted error rate $\\epsilon_j$ using $W$: $\\epsilon_j=\\frac{\\sum_i w_i \\Delta(\\hat{y}_i, y_i)}{\\sum_i w_i}$\n",
    "    - Choose $\\alpha_j = \\log \\frac{1-\\epsilon_j}{\\epsilon_j} + \\log(K-1)$\n",
    "    - Update $W$ using: $w_i \\leftarrow w_i \\exp(\\alpha_j \\Delta(\\hat{y_i}, y_i)) $\n",
    "    - Normalize $W$ to have sum 1\n",
    "- Global estimator is $H = \\sum_j \\alpha_j h_j$,\n",
    "\n",
    "the $\\Delta$ function equals to 1 when the two argument are different, 0 otherwise.\n",
    "\n",
    "To understand how we implement $H$, imaging we have two classes, and we boosted for 3 rounds to get $(h_1, h_2, h_3)$,\n",
    "with weights $(\\alpha_1, \\alpha_2, \\alpha_3)$. When we want to predict the label of sample $x$, we get $(h_1(x), h_2(x), h_3(x)) = (0,1,0)$.\n",
    "\n",
    "In this case, label $0$ gets a weight $\\alpha_1+\\alpha_2$, while class $1$ get weight $\\alpha_2$. The predicted class is the one with\n",
    "the largest weight (1 if $\\alpha_2 > \\alpha_1 + \\alpha_3$, 0 otherwise)\n",
    "\n",
    "<br>\n",
    "\n",
    "**Q3.1 (Bonus)** [3 points] Complete `fit` by building `n_estimators` of DecisionTreeClassifier, each trained on the same data but with different samples weights as detailed in the algorithm. Keep track of $(\\alpha_i)$\n",
    "\n",
    "_Hint: our weak learner (DecisionTreeClassifier) can take an argument `sample_weight` when calling the `fit` method, you'll have to use it to provide the weights $W$_\n",
    " \n",
    "\n",
    "**Q3.2 (Bonus)** [3 points] Complete `predict` method: it should handle multi-class labels, this is slighlty different from the binary case seen in the hands on.\n",
    "\n",
    "Note: Notice that if the estimator is consistent (0 error rate on the training set), AdaBoost $\\alpha_j$ are no longer defined. That's why this method requires a **weak** learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "aboosting",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class AdaBoost(BaggingEnsemble):\n",
    "\n",
    "    def __init__(self, n_estimators):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            n_estimators:\n",
    "        \"\"\"\n",
    "        super(AdaBoost, self).__init__(n_estimators)\n",
    "        self.num_classes = None\n",
    "        self.alphas = []\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.estimators = []\n",
    "        self.alphas = []\n",
    "        self.num_classes = np.unique(y_train).shape[0]  # K in the algorithm\n",
    "        weights = np.ones(len(X_train)) / len(X_train)  # W in the algorithm\n",
    "        # Workspace 3.1\n",
    "        # TODO: Implement Multiclass Adaboost and keep track of the alpha_j\n",
    "        #BEGIN\n",
    "        #END\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        '''\n",
    "        get the labels returned by the global estimator defined as H\n",
    "        the predicted label is the one that accumulates the largest sum of alphas\n",
    "        '''\n",
    "        # y_hat is one-hot encoding of the multi-class labels\n",
    "        answer = 0\n",
    "        # Workspace 3.2\n",
    "        #BEGIN\n",
    "        #END\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ensemble_handler.evaluate_model(AdaBoost(40), 'AdaBoost')\n",
    "ensemble_handler.print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  **Comparison**\n",
    "\n",
    "- **(Bonus)**  Q3.3 [1 point] Run the same comparison as in 2.11 including AdaBoost, and write up your findings below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "a411a",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create a handler for ensemble_test, use the created handler for fitting different models.\n",
    "ensemble_handler = Evaluator(house_prices)\n",
    "ensemble_handler.evaluate_model(get_weak_learner(), 'weak_learner')\n",
    "# Workspace 3.3.a\n",
    "# TODO Add multiple instances of the ensemble methods. Plot and compare their performance\n",
    "#BEGIN\n",
    "#END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "a411b",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Write-up 3.3.b\n",
    "#BEGIN\n",
    "#END"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
